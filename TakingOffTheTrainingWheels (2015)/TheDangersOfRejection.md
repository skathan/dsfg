###Causation Case Study: The Dangers of Rejection  
In the era of big data, one piece of analysis that is frequently overlooked is the problem of finding patterns when there are actually no apparent patterns. In statistics this is referred to as Type I error. As scientists, we are always on the lookout for a new or interesting breakthrough that could explain a phenomenon. We hope to see a pattern in our data that explains something or that can give us an answer. Hypothesis testing’s primary goal is to limit Type I error. This is accomplished by using small alpha. For example, an alpha value of 0.05 states that there is a 1 in 20 chance that the test will show that there is something significant when in actuality there isn’t. This problem compounds when testing multiple hypotheses. When running multiple hypothesis tests, we are likely to encounter Type I error. As more data becomes available for analysis, Type I error needs to be controlled. One of my projects required testing the difference between the means of two Microarray data samples. Microarray data contains thousands of measurements but is limited in the number of observations. A common analysis approach is to measure the same genes under different conditions. If there is a significant enough difference in the amount of gene expression between the two samples, we can say that the gene is correlated with a particular phenotype. One way to do this is to take the mean of each phenotype for a particular gene and formulate a hypothesis to test whether there is a significant difference between the means. Given that we were running thousands of these tests at α= 0.05, we found several differences that were significant. The problem was that some of these could be caused by random chance. Many corrections exist to control for false indications of significance. The Bonferroni correction is one of the most conservative. This calculation lowers the level below which you will reject the null hypothesis (alpha). The formula is alpha/n, where n equals the number of hypothesis tests that you are running. Thus, if you were to run 1,000 tests of significance at α=0.05, your p value should be less than 0.00005 (0.05/1,000) to reject the null hypothesis. This is obviously a much more stringent value. A large number of the previously significant values were no longer significant, revealing the true relationships within the data.The corrected significance gave us confidence that the observed expression levels were due to differences in the cellular gene expression rather than noise. We were able to use this information to begin investigating what proteins and pathways were active in the genes expressing the phenotype of interest. By solidifying our understanding of the causal relationships, we focused our research on the areas that could lead to new discoveries about gene function and, ultimately to improved medical treatments.