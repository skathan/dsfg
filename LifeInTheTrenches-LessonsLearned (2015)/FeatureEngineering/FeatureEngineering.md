Feature Engineering
===================

<I>Feature engineering is a lot like oxygen. You can’t do without it, but you rarely give it much thought.</I>

Feature engineering is the process by which one establishes the representation of data in the context of an analytic approach. It is the foundational skill in Data Science. Without feature engineering, it would not be possible to understand and represent the world through a mathematical model. Feature engineering is a challenging art. Like other arts, it is a creative process that manifests uniquely in each Data Scientist. It will be influenced substantially by the scientist’s experiences, tastes and understanding of the field. <br>

When faced with the problem of feature engineering, there are several paths that one may initially take. Generally speaking, better features can be developed with more knowledge of the domain. One approach to feature engineering is to begin by describing smaller elements of the domain and continuously constructing more intricate features as the model becomes more complex. These more complicated features can be defined by considering other attributes of the domain, aggregating features together into different groups or using advanced statistical and mathematical techniques to devise new features. The ultimate judge in this process is the performance of the machine learning algorithm which makes decisions based on this feature vector. 

Consider the example of email spam classification. Because the domain is a set of emails, one possible choice of an initial feature vector is the integer array that counts the number of times a given word appears in the email. This is called the "bag of words" assumption, where the order that words appear in a text is ignored. If an algorithm with this feature vector does not adequately distinguish between spam and non-spam emails, a feature could be added that counts the number of misspelled words in the text. This new feature uses the spam recognition domain knowledge that asserts many spam emails misspell words. These misspelled words alert filters saying that the existence of certain words automatically label an email as spam. If this new feature is not enough, there are still additional features to be considered such as whether or not a first or last name is used in the email. 

Feature engineering represents a complex, but crucial aspect of Data Science. The Learning Optimal Features sidebar goes into detail about feature learning – an automated approach to feature engineering that applies machine learning techniques.

#What differentiates a great model from a bad one?

In most cases, the inputs to the model matter even more than the choice of the algorithm. The traditional approach has a two-step process where heuristics and subject-matter expertise are used to find a good set of features, and then algorithms optimize model parameters. Deep learning combines these steps into one. Feature engineering, feature selection, and model parameter estimation are accomplished simultaneously. This reduces the need for highlyspecialized domain knowledge and often results in better models. 

For example, in the context of images from the natural world, deep networks may learn low-level features such as lines at various angles and curved lines. Middle layers may combine the lower-level features into more complex geometric shapes and patterns. Higher-level layers combine the midlevel features into more complicated features that begin to resemble faces and shapes of animals. Applied to other types of data, such as audio and text, deep neural networks learn increasingly sophisticated features at each layer in a similar manner.
